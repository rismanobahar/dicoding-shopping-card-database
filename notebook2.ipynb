{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Analytical Data Project: [Shopping Card Database]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0raob58DC0"
      },
      "source": [
        "## Determine Business Problems(QUESTIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQeQ5YF8DC0"
      },
      "source": [
        "1. How has the company's sales and revenue performed in recent months?\n",
        "2. What are the most and least sold products?\n",
        "3. What are our customer demographics?\n",
        "4. When did the customer last make a transaction?\n",
        "5. How often has a customer made a purchase in the last few months?\n",
        "6. How much money did the customer spend in the last few months?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVYwaObI8DC1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sh51Xy8DC1"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXU2GBYu8DC1"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjCBk1BI8DC1"
      },
      "outputs": [],
      "source": [
        "# Loading the customers data\n",
        "customers_df = pd.read_csv(\"https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/customers.csv\")\n",
        "customers_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the orders data\n",
        "orders_df = pd.read_csv(\"https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/orders.csv\")\n",
        "orders_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the product data\n",
        "product_df = pd.read_csv(\"https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/products.csv\")\n",
        "product_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loading the sales data\n",
        "sales_df = pd.read_csv(\"https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/DicodingCollection/sales.csv\")\n",
        "sales_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMi6xGaDkbCi"
      },
      "source": [
        "**Insight:**\n",
        "- Okay, now we have successfully loaded all the required data. The next stage is to assess the quality of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSiqaZp8DC1"
      },
      "source": [
        "### Assessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax-3tEjc9Cj1"
      },
      "outputs": [],
      "source": [
        "customers_df.info()\n",
        "customers_df.isna().sum()\n",
        "print(\"Jumlah duplikasi: \", customers_df.duplicated().sum())    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customers_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders_df.info()\n",
        "print(\"Jumlah duplikasi: \",orders_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "orders_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "product_df.info()\n",
        "print(\"Jumlah duplikasi: \", product_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "product_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_df.info()\n",
        "sales_df.isna().sum()\n",
        "print(\"Jumlah duplikasi: \", sales_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sales_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dtxhAPrkhPL"
      },
      "source": [
        "**Insight:**\n",
        "- **costumers_df** = If you pay attention, there is a strangeness in the maximum value contained in the age column. This is most likely due to the presence of an inaccurate value in the column. We will also clean up this problem in the data cleaning stage.\n",
        "- **orders_df** = If you pay attention, there is no strangeness in the results. This shows that there is no duplication and strangeness of values in orders_df.\n",
        "- **product_df** = Based on the image above, it can be seen that there are 6 duplicated data in product_df. In the data cleaning stage, we will remove the duplication.\n",
        "- **sales_df** = The above results show that there is no duplication in the sales_df. In addition, it also shows that there is no strangeness in the summary of statistical parameters from sales_df."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhN5R4hr8DC1"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CUSTOMERS_DF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVnYpprE9Evz"
      },
      "outputs": [],
      "source": [
        "### CLEANING customers_df Data\n",
        "\n",
        "# Based on the results of the data assessment process, it is known that there are three problems\n",
        "# encountered in the customer_df, namely duplicate data, missing value, and inaccurate value. At\n",
        "# this stage, we will clear up all three problems.\n",
        "\n",
        "# Eliminating duplicate data\n",
        "\n",
        "# The first problem we will deal with is duplicate data. As we have learned before, when we find\n",
        "# duplicates in the data, we must eliminate or delete those duplicates. Well, to do this, we can\n",
        "# make use of the drop_duplicates() method. Here is the code to remove duplicates on customer_df.\n",
        "\n",
        "customers_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# After running the above code, double-check that there are still duplicates in the data by \n",
        "# running the following code.\n",
        "\n",
        "print(\"Jumlah duplikasi: \", customers_df.duplicated().sum())\n",
        "\n",
        "# If the deduplication process goes smoothly, the above code will produce an output indicating \n",
        "# the absence of duplicates on the customers_df.\n",
        "\n",
        "# Dealing with missing value\n",
        "\n",
        "# The next problem we have to deal with is the missing value in the gender column. Well, in \n",
        "# general, there are three methods to overcome missing value, namely dropping, imputation, and \n",
        "# interpolation. To determine which method to use, we need to look at the data that contains the\n",
        "# missing value using the following filtering technique.\n",
        "\n",
        "customers_df[customers_df.gender.isna()]\n",
        "\n",
        "# The above code will only display rows of data that meet the condition customers_df.gender.isna()\n",
        "# or in other words it will display rows of data that contain missing values in the gender column.\n",
        "# Here's what the row of data looks like.\n",
        "\n",
        "# Based on the image above, it can be seen that the data row still contains a lot of important\n",
        "# information so it would be a pity if it was thrown away immediately. Therefore, in this case,\n",
        "# we will use the imputation method to handle the missing value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In the imputation method, we will use a specific value to replace the missing value. The gender\n",
        "# column is a categorical column, we will use the dominant value as a substitute for the missing\n",
        "# value. Use the value_counts() method to identify the dominant value.\n",
        "\n",
        "customers_df.gender.value_counts()\n",
        "\n",
        "# The above code will produce the following output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Based on the results above, it can be seen that the most dominant value in the gender column is\n",
        "# \"Prefer not to say\". This value is what we will use next as a substitute for missing value.\n",
        "# This replacement process can be done using the fillna() method as in the following example.\n",
        "\n",
        "customers_df.fillna(value=\"Prefer not to say\", inplace=True)\n",
        "\n",
        "# To make sure the above process is running properly, we can re-run the code to identify the\n",
        "# missing value as follows.\n",
        "\n",
        "customers_df.isna().sum()\n",
        "\n",
        "# If the missing value cleanup process is successful, you will get the following results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handling the innacurate value\n",
        "\n",
        "# Okay, now we're going to solve the problem of inaccurate values in the age column. For starters,\n",
        "# we need to look at the data row data that contains the inaccurate value (the row with the \n",
        "# maximum age value). This is done using a filter technique like the following code example.\n",
        "\n",
        "customers_df[customers_df.age == customers_df.age.max()]\n",
        "\n",
        "# The code above will display the rows of data that have the maximum age value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Based on this data, we can assume that the inaccurate value occurred due to human error so that\n",
        "# the excess entered a zero value. Therefore, replace it with a value of 70. This process is done\n",
        "# by utilizing the replace() method as shown in the following example.\n",
        "\n",
        "customers_df.age.replace(customers_df.age.max(), 70, inplace=True)\n",
        "\n",
        "# Well, to make sure the code above runs as expected, run the following code again.\n",
        "\n",
        "customers_df[customers_df.age == customers_df.age.max()]\n",
        "\n",
        "# Upsi, it turns out that there are still other invalid values contained in the age column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The cause of this error is likely to be the same as before, namely human error that is\n",
        "# overloaded with a zero value. To handle this, we'll replace it with a value of 50.\n",
        "\n",
        "customers_df.age.replace(customers_df.age.max(), 50, inplace=True)\n",
        "\n",
        "# To make sure there are no inaccurate values in the customers_df, run the following code.\n",
        "\n",
        "customers_df.describe()\n",
        "\n",
        "# The above code will produce the following output!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ORDERS_DF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLEANING orders_df Data\n",
        "\n",
        "# Okay, now we have solved all the problems that exist in customers_df. Next, we will overcome\n",
        "# the problem in orders_df. Based on the previous data assessment process, it is known that there\n",
        "# is a data type error for the order_date & delivery_date columns. To solve this problem, we'll\n",
        "# replace the data type in the order_date & delivery_date columns to datetime. This process can \n",
        "# be done using  the to_datetime() function provided by the pandas library. Here's an example\n",
        "# code to do so.\n",
        "\n",
        "datetime_columns = [\"order_date\", \"delivery_date\"]\n",
        " \n",
        "for column in datetime_columns:\n",
        "  orders_df[column] = pd.to_datetime(orders_df[column])\n",
        "\n",
        "# The above code will change the data type in the order_date & delivery_date columns to datetime.\n",
        "# To make sure this works as expected, double-check the data type using the info() method.\n",
        "\n",
        "orders_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PRODUCT_DF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLEANING product_df Data\n",
        "\n",
        "# The next data we will clean up is product_df. According to the results of the previous data\n",
        "# assessment, we know that there are 6 duplicate data in product_df. To solve this, we need to\n",
        "# discard the same data using the drop_duplicates() method as in the following example.\n",
        "\n",
        "product_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# The code above will delete all duplicate data. To make sure the code works as expected, run the following code.\n",
        "\n",
        "print(\"Jumlah duplikasi: \", product_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**SALES_DF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLEANING sales_df Data\n",
        "\n",
        "# The next data you need to clean up is sales_df. Based on the results of the previous data\n",
        "# analysis, it is known that there are 19 missing values in the total_price column. To find\n",
        "# out the most appropriate process for handling missing values, we need to first look at the\n",
        "# data rows that contain the missing values.\n",
        "\n",
        "sales_df[sales_df.total_price.isna()]\n",
        "\n",
        "# The code above will display all the rows of data that have missing values in the total_price\n",
        "# column as shown in the following image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Based on the display of the data, we find that the value of total_price is the result of\n",
        "# multiplication between price_per_unit and quantity. We can use this pattern to handle missing\n",
        "# values in total_price columns. Here's an example of implementing code to do this.\n",
        "\n",
        "sales_df[\"total_price\"] = sales_df[\"price_per_unit\"] * sales_df[\"quantity\"]\n",
        "\n",
        "# The code above will address all missing values and ensure that the values in total_price\n",
        "# columns are correct. To make sure of this, you can double-check the number of missing values\n",
        "# on the sales_df using the following code.\n",
        "\n",
        "sales_df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_5ejIqckiSP"
      },
      "source": [
        "**Insight:**\n",
        "- **customers_df** = Based on these results, it can be seen that the age column has a maximum value that is quite reasonable. In addition, if you pay attention, the mean and standard deviation values also change after we deal with the inaccurate value.\n",
        "- **orders_df** = If all stages go as expected, the above code will produce the following output.\n",
        "- **product_df** = If the process of deleting duplicate data goes smoothly, the above code will produce an output like the following \"Number of duplicates: 0\".\n",
        "- **sales_df** = If the previous process went smoothly, you will find the following results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-Y6wU38DC1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW7WF2kr8DC1"
      },
      "source": [
        "### Explore ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9CQCZjk8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th_Lzl2Fkj9O"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsyZjqak8DC2"
      },
      "source": [
        "## Visualization & Explanatory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxOiQ6n8DC2"
      },
      "source": [
        "### Pertanyaan 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swJUdAD8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgHI7CiU8DC2"
      },
      "source": [
        "### Pertanyaan 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0lCsvO8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-36BDLklRg"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y4VUsmcYNZ5"
      },
      "source": [
        "## Analisis Lanjutan (Opsional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWhnzsJGYUCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WeHlCeX8DC2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTcyR48Y8DC2"
      },
      "source": [
        "- Conclution pertanyaan 1\n",
        "- Conclution pertanyaan 2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:21:23) [MSC v.1916 32 bit (Intel)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
